{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla RNN & LSTM & GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "timesteps = 10 # 시점의 수 / NLP에서는 보통 문장의 길이\n",
    "input_size = 4 # 입력의 차원 / NLP에서는 보통 단어 벡터의 차원\n",
    "hidden_size = 8 # 은닉 상태의 크기 / 메모리 셀의 용량\n",
    "\n",
    "inputs = np.random.random((timesteps, input_size))\n",
    "hidden_state_t = np.zeros((hidden_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n",
      "(8, 8)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "Wx = np.random.random((hidden_size, input_size))  \n",
    "Wh = np.random.random((hidden_size, hidden_size)) \n",
    "b = np.random.random((hidden_size,))\n",
    "print(np.shape(Wx))\n",
    "print(np.shape(Wh))\n",
    "print(np.shape(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n",
      "(2, 8)\n",
      "(3, 8)\n",
      "(4, 8)\n",
      "(5, 8)\n",
      "(6, 8)\n",
      "(7, 8)\n",
      "(8, 8)\n",
      "(9, 8)\n",
      "(10, 8)\n",
      "[[0.9998587  0.99999752 0.99997699 0.99990103 0.999977   0.9997965\n",
      "  0.99998285 0.99999749]\n",
      " [0.99977423 0.99999739 0.99997543 0.99991078 0.99998481 0.99978208\n",
      "  0.99998649 0.99999801]\n",
      " [0.99982054 0.999998   0.99997353 0.99989504 0.99998022 0.99987225\n",
      "  0.99998546 0.99999743]\n",
      " [0.99970932 0.99999213 0.99992884 0.99963139 0.99994414 0.99950784\n",
      "  0.99992932 0.99999273]\n",
      " [0.99977301 0.9999963  0.99996288 0.99982124 0.99997419 0.99975988\n",
      "  0.99996971 0.99999616]\n",
      " [0.99985216 0.99999792 0.99999045 0.99994917 0.99999432 0.99975235\n",
      "  0.99998844 0.99999888]\n",
      " [0.999836   0.99999838 0.99998151 0.99992364 0.99998745 0.99988506\n",
      "  0.99998889 0.99999813]\n",
      " [0.99976969 0.99999495 0.99996059 0.99979216 0.99997087 0.99963187\n",
      "  0.99995876 0.9999957 ]\n",
      " [0.99990079 0.99999911 0.99999162 0.99996242 0.99999348 0.99992237\n",
      "  0.99999396 0.99999896]\n",
      " [0.99989966 0.99999881 0.99999464 0.99996527 0.99999675 0.99986328\n",
      "  0.99999166 0.99999917]]\n"
     ]
    }
   ],
   "source": [
    "total_hidden_states = []\n",
    "\n",
    "for input_t in inputs:\n",
    "  output_t = np.tanh(np.dot(Wx,input_t) + np.dot(Wh,hidden_state_t) + b)\n",
    "  total_hidden_states.append(list(output_t)) \n",
    "  print(np.shape(total_hidden_states))\n",
    "  hidden_state_t = output_t\n",
    "\n",
    "total_hidden_states = np.stack(total_hidden_states, axis = 0) \n",
    "\n",
    "print(total_hidden_states) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5 \n",
    "hidden_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (batch_size, time_steps, input_size)\n",
    "inputs = torch.Tensor(1, 10, 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = nn.RNN(input_size, hidden_size, batch_first=True) # batch_first: 차원의 순서 중 batch가 가장 처음에 오는지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 8])\n",
      "torch.Size([1, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "outputs, _status = cell(inputs)\n",
    "print(outputs.shape) # 모든 time-step의 hidden_state\n",
    "print(_status.shape) # 최종 time-step의 hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (batch_size, time_steps, input_size)\n",
    "inputs = torch.Tensor(1, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 8])\n"
     ]
    }
   ],
   "source": [
    "cell = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 2, batch_first=True) # num_layers: 은닉층 개수\n",
    "outputs, _status = cell(inputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "print(_status.shape) # (층의 개수, 배치 크기, 은닉 상태의 크기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (batch_size, time_steps, input_size)\n",
    "inputs = torch.Tensor(1, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 2, batch_first=True, bidirectional = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 16])\n",
      "torch.Size([4, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "outputs, _status = cell(inputs)\n",
    "print(outputs.shape) # (배치 크기, 시퀀스 길이, 은닉 상태의 크기 x 2)\n",
    "print(_status.shape) # (층의 개수 x 2, 배치 크기, 은닉 상태의 크기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "# nn.LSTM(input_dim, hidden_size, batch_fisrt=True)  \n",
    "\n",
    "# GRU\n",
    "# nn.GRU(input_dim, hidden_size, batch_fisrt=True)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
