{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention mechanism를 이용한 번역기 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 33000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "  # NFD: 유니코드 문자열을 정규화하는 방법 중 하나로, 악센트 문자를 기본 문자와 결합 문자로 분리함\n",
    "  # Mn: Non-Spacing Mark(악센트 등)를 나타내는 카테고리\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "  sent = unicode_to_ascii(sent.lower())\n",
    "  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "  sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "  return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "  encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "  with open(\"fra.txt\", \"r\") as lines:\n",
    "    for i, line in enumerate(lines):\n",
    "      src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "      src_line = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "      tar_line = preprocess_sentence(tar_line)\n",
    "      tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "      tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "      encoder_input.append(src_line)\n",
    "      decoder_input.append(tar_line_in)\n",
    "      decoder_target.append(tar_line_out)\n",
    "\n",
    "      if i == num_samples - 1:\n",
    "        break\n",
    "\n",
    "  return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 영어 문장 : Have you had dinner?\n",
      "전처리 후 영어 문장 : have you had dinner ?\n",
      "전처리 전 프랑스어 문장 : Avez-vous déjà diné?\n",
      "전처리 후 프랑스어 문장 : avez vous deja dine ?\n"
     ]
    }
   ],
   "source": [
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné?\"\n",
    "\n",
    "print('전처리 전 영어 문장 :', en_sent)\n",
    "print('전처리 후 영어 문장 :',preprocess_sentence(en_sent))\n",
    "print('전처리 전 프랑스어 문장 :', fr_sent)\n",
    "print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
      "디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n",
      "디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "print('인코더의 입력 :',sents_en_in[:5])\n",
    "print('디코더의 입력 :',sents_fra_in[:5])\n",
    "print('디코더의 레이블 :',sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sents):\n",
    "  word_list = []\n",
    "\n",
    "  for sent in sents:\n",
    "      for word in sent:\n",
    "        word_list.append(word)\n",
    "\n",
    "  word_counts = Counter(word_list)\n",
    "  vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "  word_to_index = {}\n",
    "  word_to_index['<PAD>'] = 0\n",
    "  word_to_index['<UNK>'] = 1\n",
    "\n",
    "  for index, word in enumerate(vocab) :\n",
    "    word_to_index[word] = index + 2\n",
    "\n",
    "  return word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4482, 프랑스어 단어 집합의 크기 : 7874\n"
     ]
    }
   ],
   "source": [
    "src_vocab = build_vocab(sents_en_in)\n",
    "tar_vocab = build_vocab(sents_fra_in + sents_fra_out)\n",
    "\n",
    "src_vocab_size = len(src_vocab)\n",
    "tar_vocab_size = len(tar_vocab)\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = {v: k for k, v in src_vocab.items()}\n",
    "index_to_tar = {v: k for k, v in tar_vocab.items()}\n",
    "\n",
    "def texts_to_sequences(sents, word_to_index):\n",
    "  encoded_X_data = []\n",
    "  for sent in tqdm(sents):\n",
    "    index_sequences = []\n",
    "    for word in sent:\n",
    "      try:\n",
    "          index_sequences.append(word_to_index[word])\n",
    "      except KeyError:\n",
    "          index_sequences.append(word_to_index['<UNK>'])\n",
    "    encoded_X_data.append(index_sequences)\n",
    "  return encoded_X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33000/33000 [00:00<00:00, 384207.85it/s]\n",
      "100%|██████████| 33000/33000 [00:00<00:00, 2242325.59it/s]\n",
      "100%|██████████| 33000/33000 [00:00<00:00, 405052.27it/s]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = texts_to_sequences(sents_en_in, src_vocab)\n",
    "decoder_input = texts_to_sequences(sents_fra_in, tar_vocab)\n",
    "decoder_target = texts_to_sequences(sents_fra_out, tar_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 1, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 2, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 3, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 4, 정수 인코딩 전: ['hi', '.'], 정수 인코딩 후: [744, 2]\n"
     ]
    }
   ],
   "source": [
    "for i, (item1, item2) in zip(range(5), zip(sents_en_in, encoder_input)):\n",
    "    print(f\"Index: {i}, 정수 인코딩 전: {item1}, 정수 인코딩 후: {item2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sentences, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = max([len(sentence) for sentence in sentences])\n",
    "\n",
    "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        if len(sentence) != 0:\n",
    "            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input)\n",
    "decoder_input = pad_sequences(decoder_input)\n",
    "decoder_target = pad_sequences(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력의 크기(shape) : (33000, 7)\n",
      "디코더의 입력의 크기(shape) : (33000, 16)\n",
      "디코더의 레이블의 크기(shape) : (33000, 16)\n"
     ]
    }
   ],
   "source": [
    "print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n",
    "print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n",
    "print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 시퀀스 : [11244  4137 16576 ... 20398  2046 10744]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print('랜덤 시퀀스 :',indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'love', 'this', 'group', '.', '<PAD>', '<PAD>']\n",
      "['<sos>', 'j', 'aime', 'ce', 'groupe', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['j', 'aime', 'ce', 'groupe', '.', '<eos>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "print([index_to_src[word] for word in encoder_input[30997]])\n",
    "print([index_to_tar[word] for word in decoder_input[30997]])\n",
    "print([index_to_tar[word] for word in decoder_target[30997]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터의 개수 : 3300\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(33000*0.1)\n",
    "print('검증 데이터의 개수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 source 데이터의 크기 : (29700, 7)\n",
      "훈련 target 데이터의 크기 : (29700, 16)\n",
      "훈련 target 레이블의 크기 : (29700, 16)\n",
      "테스트 source 데이터의 크기 : (3300, 7)\n",
      "테스트 target 데이터의 크기 : (3300, 16)\n",
      "테스트 target 레이블의 크기 : (3300, 16)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
    "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
    "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
    "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
    "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
    "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "embedding_dim = 256\n",
    "hidden_units = 256\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, src_vocab_size, embedding_dim, hidden_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(src_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(x)\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, tar_vocab_size, embedding_dim, hidden_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(tar_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim + hidden_units, hidden_units, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_units, tar_vocab_size)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x, encoder_outputs, hidden, cell):\n",
    "        x = self.embedding(x)\n",
    "        attention_scores = torch.bmm(encoder_outputs, hidden.transpose(0, 1).transpose(1, 2))\n",
    "        attention_weights = self.softmax(attention_scores)\n",
    "        context_vector = torch.bmm(attention_weights.transpose(1, 2), encoder_outputs)\n",
    "        seq_len = x.shape[1]\n",
    "        context_vector_repeated = context_vector.repeat(1, seq_len, 1)\n",
    "        x = torch.cat((x, context_vector_repeated), dim=2)        \n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        output = self.fc(output)\n",
    "        return output, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        encoder_outputs, hidden, cell = self.encoder(src)\n",
    "        output, _, _ = self.decoder(trg, encoder_outputs, hidden, cell)\n",
    "        return output\n",
    "\n",
    "encoder = Encoder(src_vocab_size, embedding_dim, hidden_units)\n",
    "decoder = Decoder(tar_vocab_size, embedding_dim, hidden_units)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(4482, 256, padding_idx=0)\n",
      "    (lstm): LSTM(256, 256, batch_first=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(7874, 256, padding_idx=0)\n",
      "    (lstm): LSTM(512, 256, batch_first=True)\n",
      "    (fc): Linear(in_features=256, out_features=7874, bias=True)\n",
      "    (softmax): Softmax(dim=2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader, loss_function, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for encoder_inputs, decoder_inputs, decoder_targets in dataloader:\n",
    "            encoder_inputs = encoder_inputs.to(device)\n",
    "            decoder_inputs = decoder_inputs.to(device)\n",
    "            decoder_targets = decoder_targets.to(device)\n",
    "\n",
    "            outputs = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "            loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            mask = decoder_targets != 0\n",
    "            total_correct += ((outputs.argmax(dim=-1) == decoder_targets) * mask).sum().item()\n",
    "            total_count += mask.sum().item()\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(4482, 256, padding_idx=0)\n",
       "    (lstm): LSTM(256, 256, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(7874, 256, padding_idx=0)\n",
       "    (lstm): LSTM(512, 256, batch_first=True)\n",
       "    (fc): Linear(in_features=256, out_features=7874, bias=True)\n",
       "    (softmax): Softmax(dim=2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_train_tensor = torch.tensor(encoder_input_train, dtype=torch.long)\n",
    "decoder_input_train_tensor = torch.tensor(decoder_input_train, dtype=torch.long)\n",
    "decoder_target_train_tensor = torch.tensor(decoder_target_train, dtype=torch.long)\n",
    "\n",
    "encoder_input_test_tensor = torch.tensor(encoder_input_test, dtype=torch.long)\n",
    "decoder_input_test_tensor = torch.tensor(decoder_input_test, dtype=torch.long)\n",
    "decoder_target_test_tensor = torch.tensor(decoder_target_test, dtype=torch.long)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = TensorDataset(encoder_input_train_tensor, decoder_input_train_tensor, decoder_target_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(encoder_input_test_tensor, decoder_input_test_tensor, decoder_target_test_tensor)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_epochs = 30\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 | Train Loss: 2.9416 | Train Acc: 0.5419 | Valid Loss: 3.0714 | Valid Acc: 0.5337\n",
      "Validation loss improved from inf to 3.0714. 체크포인트를 저장합니다.\n",
      "Epoch: 2/30 | Train Loss: 2.2388 | Train Acc: 0.6167 | Valid Loss: 2.4771 | Valid Acc: 0.5983\n",
      "Validation loss improved from 3.0714 to 2.4771. 체크포인트를 저장합니다.\n",
      "Epoch: 3/30 | Train Loss: 1.7508 | Train Acc: 0.6693 | Valid Loss: 2.1174 | Valid Acc: 0.6386\n",
      "Validation loss improved from 2.4771 to 2.1174. 체크포인트를 저장합니다.\n",
      "Epoch: 4/30 | Train Loss: 1.3958 | Train Acc: 0.7159 | Valid Loss: 1.8888 | Valid Acc: 0.6663\n",
      "Validation loss improved from 2.1174 to 1.8888. 체크포인트를 저장합니다.\n",
      "Epoch: 5/30 | Train Loss: 1.1117 | Train Acc: 0.7604 | Valid Loss: 1.7251 | Valid Acc: 0.6846\n",
      "Validation loss improved from 1.8888 to 1.7251. 체크포인트를 저장합니다.\n",
      "Epoch: 6/30 | Train Loss: 0.8788 | Train Acc: 0.8014 | Valid Loss: 1.6023 | Valid Acc: 0.6977\n",
      "Validation loss improved from 1.7251 to 1.6023. 체크포인트를 저장합니다.\n",
      "Epoch: 7/30 | Train Loss: 0.7031 | Train Acc: 0.8351 | Valid Loss: 1.5192 | Valid Acc: 0.7099\n",
      "Validation loss improved from 1.6023 to 1.5192. 체크포인트를 저장합니다.\n",
      "Epoch: 8/30 | Train Loss: 0.5684 | Train Acc: 0.8659 | Valid Loss: 1.4605 | Valid Acc: 0.7234\n",
      "Validation loss improved from 1.5192 to 1.4605. 체크포인트를 저장합니다.\n",
      "Epoch: 9/30 | Train Loss: 0.4639 | Train Acc: 0.8846 | Valid Loss: 1.4283 | Valid Acc: 0.7256\n",
      "Validation loss improved from 1.4605 to 1.4283. 체크포인트를 저장합니다.\n",
      "Epoch: 10/30 | Train Loss: 0.3906 | Train Acc: 0.8983 | Valid Loss: 1.4139 | Valid Acc: 0.7297\n",
      "Validation loss improved from 1.4283 to 1.4139. 체크포인트를 저장합니다.\n",
      "Epoch: 11/30 | Train Loss: 0.3322 | Train Acc: 0.9072 | Valid Loss: 1.4072 | Valid Acc: 0.7312\n",
      "Validation loss improved from 1.4139 to 1.4072. 체크포인트를 저장합니다.\n",
      "Epoch: 12/30 | Train Loss: 0.2941 | Train Acc: 0.9142 | Valid Loss: 1.4111 | Valid Acc: 0.7297\n",
      "Epoch: 13/30 | Train Loss: 0.2622 | Train Acc: 0.9189 | Valid Loss: 1.4101 | Valid Acc: 0.7350\n",
      "Epoch: 14/30 | Train Loss: 0.2393 | Train Acc: 0.9230 | Valid Loss: 1.4193 | Valid Acc: 0.7353\n",
      "Epoch: 15/30 | Train Loss: 0.2244 | Train Acc: 0.9254 | Valid Loss: 1.4326 | Valid Acc: 0.7343\n",
      "Epoch: 16/30 | Train Loss: 0.2121 | Train Acc: 0.9268 | Valid Loss: 1.4407 | Valid Acc: 0.7345\n",
      "Epoch: 17/30 | Train Loss: 0.2016 | Train Acc: 0.9276 | Valid Loss: 1.4495 | Valid Acc: 0.7359\n",
      "Epoch: 18/30 | Train Loss: 0.1929 | Train Acc: 0.9292 | Valid Loss: 1.4627 | Valid Acc: 0.7352\n",
      "Epoch: 19/30 | Train Loss: 0.1863 | Train Acc: 0.9288 | Valid Loss: 1.4737 | Valid Acc: 0.7356\n",
      "Epoch: 20/30 | Train Loss: 0.1800 | Train Acc: 0.9299 | Valid Loss: 1.4833 | Valid Acc: 0.7365\n",
      "Epoch: 21/30 | Train Loss: 0.1757 | Train Acc: 0.9305 | Valid Loss: 1.4949 | Valid Acc: 0.7335\n",
      "Epoch: 22/30 | Train Loss: 0.1741 | Train Acc: 0.9308 | Valid Loss: 1.5092 | Valid Acc: 0.7356\n",
      "Epoch: 23/30 | Train Loss: 0.1682 | Train Acc: 0.9314 | Valid Loss: 1.5218 | Valid Acc: 0.7355\n",
      "Epoch: 24/30 | Train Loss: 0.1652 | Train Acc: 0.9315 | Valid Loss: 1.5230 | Valid Acc: 0.7338\n",
      "Epoch: 25/30 | Train Loss: 0.1632 | Train Acc: 0.9320 | Valid Loss: 1.5265 | Valid Acc: 0.7382\n",
      "Epoch: 26/30 | Train Loss: 0.1595 | Train Acc: 0.9321 | Valid Loss: 1.5354 | Valid Acc: 0.7367\n",
      "Epoch: 27/30 | Train Loss: 0.1592 | Train Acc: 0.9317 | Valid Loss: 1.5563 | Valid Acc: 0.7361\n",
      "Epoch: 28/30 | Train Loss: 0.1558 | Train Acc: 0.9322 | Valid Loss: 1.5529 | Valid Acc: 0.7365\n",
      "Epoch: 29/30 | Train Loss: 0.1562 | Train Acc: 0.9325 | Valid Loss: 1.5570 | Valid Acc: 0.7358\n",
      "Epoch: 30/30 | Train Loss: 0.1555 | Train Acc: 0.9318 | Valid Loss: 1.5670 | Valid Acc: 0.7366\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for encoder_inputs, decoder_inputs, decoder_targets in train_dataloader:\n",
    "        encoder_inputs = encoder_inputs.to(device)\n",
    "        decoder_inputs = decoder_inputs.to(device)\n",
    "        decoder_targets = decoder_targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "        loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss, train_acc = evaluation(model, train_dataloader, loss_function, device)\n",
    "    valid_loss, valid_acc = evaluation(model, valid_dataloader, loss_function, device)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f}')\n",
    "\n",
    "    if valid_loss < best_val_loss:\n",
    "        print(f'Validation loss improved from {best_val_loss:.4f} to {valid_loss:.4f}. 체크포인트를 저장합니다.')\n",
    "        best_val_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model validation loss: 1.4072\n",
      "Best model validation accuracy: 0.7312\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "val_loss, val_accuracy = evaluation(model, valid_dataloader, loss_function, device)\n",
    "\n",
    "print(f'Best model validation loss: {val_loss:.4f}')\n",
    "print(f'Best model validation accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(tar_vocab['<sos>'])\n",
    "print(tar_vocab['<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = {v: k for k, v in src_vocab.items()}\n",
    "index_to_tar = {v: k for k, v in tar_vocab.items()}\n",
    "\n",
    "def seq_to_src(input_seq):\n",
    "  sentence = ''\n",
    "  for encoded_word in input_seq:\n",
    "    if(encoded_word != 0):\n",
    "      sentence = sentence + index_to_src[encoded_word] + ' '\n",
    "  return sentence\n",
    "\n",
    "def seq_to_tar(input_seq):\n",
    "  sentence = ''\n",
    "  for encoded_word in input_seq:\n",
    "    if(encoded_word != 0 and encoded_word != tar_vocab['<sos>'] and encoded_word != tar_vocab['<eos>']):\n",
    "      sentence = sentence + index_to_tar[encoded_word] + ' '\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3 338  19   2   0   0   0]\n",
      "[  3  14 842  70   2   0   0   0   0   0   0   0   0   0   0   0]\n",
      "[ 14 842  70   2   4   0   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_test[25])\n",
    "print(decoder_input_test[25])\n",
    "print(decoder_target_test[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, max_output_len, int_to_src_token, int_to_tar_token):\n",
    "    encoder_inputs = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    encoder_outputs, hidden, cell = model.encoder(encoder_inputs)\n",
    "\n",
    "    decoder_input = torch.tensor([3], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    decoded_tokens = []\n",
    "\n",
    "    for _ in range(max_output_len):\n",
    "        output, hidden, cell = model.decoder(decoder_input, encoder_outputs, hidden, cell)\n",
    "\n",
    "        output_token = output.argmax(dim=-1).item()\n",
    "\n",
    "        if output_token == 4:\n",
    "            break\n",
    "\n",
    "        decoded_tokens.append(output_token)\n",
    "\n",
    "        decoder_input = torch.tensor([output_token], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    return ' '.join(int_to_tar_token[token] for token in decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : you may go . \n",
      "정답문장 : vous pouvez vous en aller . \n",
      "번역문장 : tu peux y aller .\n",
      "--------------------------------------------------\n",
      "입력문장 : are you registered ? \n",
      "정답문장 : etes vous inscrit ? \n",
      "번역문장 : etes vous inscrits ?\n",
      "--------------------------------------------------\n",
      "입력문장 : we had to stop . \n",
      "정답문장 : il nous fallait cesser . \n",
      "번역문장 : il nous fallut cesser .\n",
      "--------------------------------------------------\n",
      "입력문장 : let s forget it . \n",
      "정답문장 : oublions tout ca . \n",
      "번역문장 : oublions ca .\n",
      "--------------------------------------------------\n",
      "입력문장 : may i be excused ? \n",
      "정답문장 : puis je etre excuse ? \n",
      "번역문장 : puis je etre excuse ?\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3, 50, 100, 300, 1001]:\n",
    "  input_seq = encoder_input_train[seq_index]\n",
    "  translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
    "\n",
    "  print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
    "  print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
    "  print(\"번역문장 :\",translated_text)\n",
    "  print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : don t shoot ! \n",
      "정답문장 : ne tirez pas ! \n",
      "번역문장 : ne tire pas !\n",
      "--------------------------------------------------\n",
      "입력문장 : i can t allow it . \n",
      "정답문장 : je ne peux pas permettre ca . \n",
      "번역문장 : je ne peux pas le supporter .\n",
      "--------------------------------------------------\n",
      "입력문장 : i will watch it . \n",
      "정답문장 : je le regarderai . \n",
      "번역문장 : j y vais .\n",
      "--------------------------------------------------\n",
      "입력문장 : whose bike is it ? \n",
      "정답문장 : a qui est cette bicyclette ? \n",
      "번역문장 : a qui est ce velo ?\n",
      "--------------------------------------------------\n",
      "입력문장 : i was naive . \n",
      "정답문장 : je fus credule . \n",
      "번역문장 : j etais naif .\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3, 50, 100, 300, 1001]:\n",
    "  input_seq = encoder_input_test[seq_index]\n",
    "  translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
    "\n",
    "  print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
    "  print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
    "  print(\"번역문장 :\",translated_text)\n",
    "  print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
