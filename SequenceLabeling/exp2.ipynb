{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양방향 LSTM을 이용한 개체명인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('train.txt', <http.client.HTTPMessage at 0x15c9684d0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/12.%20RNN%20Sequence%20Labeling/dataset/train.txt\", filename=\"train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 개수:  14041\n"
     ]
    }
   ],
   "source": [
    "f = open('train.txt', 'r')\n",
    "tagged_sentences = []\n",
    "sentence = []\n",
    "\n",
    "for line in f:\n",
    "    if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
    "        if len(sentence) > 0:\n",
    "            tagged_sentences.append(sentence)\n",
    "            sentence = []\n",
    "        continue\n",
    "    splits = line.split(' ') \n",
    "    splits[-1] = re.sub(r'\\n', '', splits[-1])\n",
    "    word = splits[0].lower()\n",
    "    sentence.append([word, splits[-1]])\n",
    "\n",
    "print(\"전체 샘플 개수: \", len(tagged_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['eu', 'B-ORG'], ['rejects', 'O'], ['german', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['british', 'B-MISC'], ['lamb', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
      "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentences, ner_tags = [], [] \n",
    "for tagged_sentence in tagged_sentences: \n",
    "    sentence, tag_info = zip(*tagged_sentence)\n",
    "    sentences.append(list(sentence))\n",
    "    ner_tags.append(list(tag_info))\n",
    "\n",
    "print(sentences[0])\n",
    "print(ner_tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['only', 'france', 'and', 'britain', 'backed', 'fischler', \"'s\", 'proposal', '.']\n",
      "['O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-PER', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[12])\n",
    "print(ner_tags[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sentences, ner_tags, test_size=.2, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=.2, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 8985\n",
      "검증 데이터의 개수 : 2247\n",
      "테스트 데이터의 개수 : 2809\n",
      "훈련 데이터 레이블의 개수 : 8985\n",
      "검증 데이터 레이블의 개수 : 2247\n",
      "테스트 데이터 레이블의 개수 : 2809\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 개수 :', len(X_train))\n",
    "print('검증 데이터의 개수 :', len(X_valid))\n",
    "print('테스트 데이터의 개수 :', len(X_test))\n",
    "print('훈련 데이터 레이블의 개수 :', len(X_train))\n",
    "print('검증 데이터 레이블의 개수 :', len(X_valid))\n",
    "print('테스트 데이터 레이블의 개수 :', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['young', 'boys', '9', '1', '0', '8', '6', '19', '3']\n",
      "['hentgen', '(', '17-7', ')', 'surrendered', 'just', 'three', 'doubles', 'and', 'a', 'pair', 'of', 'singles', 'in', 'tossing', 'his', 'major-league', 'leading', 'ninth', 'complete', 'game', '.']\n"
     ]
    }
   ],
   "source": [
    "for sent in X_train[:2]:\n",
    "  print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 단어수 : 16742\n"
     ]
    }
   ],
   "source": [
    "word_list = []\n",
    "for sent in X_train:\n",
    "    for word in sent:\n",
    "      word_list.append(word)\n",
    "\n",
    "word_counts = Counter(word_list)\n",
    "print('총 단어수 :', len(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터에서의 단어 the의 등장 횟수 : 5410\n",
      "훈련 데이터에서의 단어 love의 등장 횟수 : 7\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터에서의 단어 the의 등장 횟수 :', word_counts['the'])\n",
    "print('훈련 데이터에서의 단어 love의 등장 횟수 :', word_counts['love'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "등장 빈도수 상위 10개 단어\n",
      "['the', ',', '.', 'of', 'in', 'to', 'a', ')', '(', 'and']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "print('등장 빈도수 상위 10개 단어')\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩 토큰과 UNK 토큰을 고려한 단어 집합의 크기 : 16744\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "word_to_index['<PAD>'] = 0\n",
    "word_to_index['<UNK>'] = 1\n",
    "\n",
    "for index, word in enumerate(vocab) :\n",
    "  word_to_index[word] = index + 2\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "print('패딩 토큰과 UNK 토큰을 고려한 단어 집합의 크기 :', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 <PAD>와 맵핑되는 정수 : 0\n",
      "단어 <UNK>와 맵핑되는 정수 : 1\n",
      "단어 the와 맵핑되는 정수 : 2\n"
     ]
    }
   ],
   "source": [
    "print('단어 <PAD>와 맵핑되는 정수 :', word_to_index['<PAD>'])\n",
    "print('단어 <UNK>와 맵핑되는 정수 :', word_to_index['<UNK>'])\n",
    "print('단어 the와 맵핑되는 정수 :', word_to_index['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_sequences(tokenized_X_data, word_to_index):\n",
    "  encoded_X_data = []\n",
    "  for sent in tokenized_X_data:\n",
    "    index_sequences = []\n",
    "    for word in sent:\n",
    "      try:\n",
    "          index_sequences.append(word_to_index[word])\n",
    "      except KeyError:\n",
    "          index_sequences.append(word_to_index['<UNK>'])\n",
    "    encoded_X_data.append(index_sequences)\n",
    "  return encoded_X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_X_train = texts_to_sequences(X_train, word_to_index)\n",
    "encoded_X_valid = texts_to_sequences(X_valid, word_to_index)\n",
    "encoded_X_test = texts_to_sequences(X_test, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1260, 3215, 117, 17, 21, 123, 56, 539, 23]\n",
      "[5456, 10, 8229, 9, 8230, 186, 84, 1815, 11, 8, 1073, 5, 421, 6, 8231, 35, 2043, 291, 790, 957, 267, 4]\n"
     ]
    }
   ],
   "source": [
    "for sent in encoded_X_train[:2]:\n",
    "  print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존의 첫번째 샘플 : ['young', 'boys', '9', '1', '0', '8', '6', '19', '3']\n",
      "복원된 첫번째 샘플 : ['young', 'boys', '9', '1', '0', '8', '6', '19', '3']\n"
     ]
    }
   ],
   "source": [
    "index_to_word = {}\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "decoded_sample = [index_to_word[word] for word in encoded_X_train[0]]\n",
    "print('기존의 첫번째 샘플 :', X_train[0])\n",
    "print('복원된 첫번째 샘플 :', decoded_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "태그 집합 : ['I-PER', 'B-LOC', 'I-MISC', 'I-LOC', 'B-MISC', 'B-ORG', 'I-ORG', 'O', 'B-PER']\n",
      "태그 집합의 크기 : 9\n"
     ]
    }
   ],
   "source": [
    "flatten_tags = [tag for sent in y_train for tag in sent]\n",
    "tag_vocab = list(set(flatten_tags))\n",
    "print('태그 집합 :', tag_vocab)\n",
    "print('태그 집합의 크기 :', len(tag_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "태그 집합 : {'<PAD>': 0, 'I-PER': 1, 'B-LOC': 2, 'I-MISC': 3, 'I-LOC': 4, 'B-MISC': 5, 'B-ORG': 6, 'I-ORG': 7, 'O': 8, 'B-PER': 9}\n"
     ]
    }
   ],
   "source": [
    "tag_to_index = {}\n",
    "tag_to_index['<PAD>'] = 0\n",
    "\n",
    "for index, word in enumerate(tag_vocab) :\n",
    "  tag_to_index[word] = index + 1\n",
    "\n",
    "tag_vocab_size = len(tag_to_index)\n",
    "print('태그 집합 :', tag_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_label(sequence, tag_to_index):\n",
    "  label_sequence = []\n",
    "  for seq in sequence:\n",
    "    label_sequence.append([tag_to_index[tag] for tag in seq])\n",
    "  return label_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_y_train = encoding_label(y_train, tag_to_index)\n",
    "encoded_y_valid = encoding_label(y_valid, tag_to_index)\n",
    "encoded_y_test = encoding_label(y_test, tag_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 데이터 상위 2개\n",
      "[[1260, 3215, 117, 17, 21, 123, 56, 539, 23], [5456, 10, 8229, 9, 8230, 186, 84, 1815, 11, 8, 1073, 5, 421, 6, 8231, 35, 2043, 291, 790, 957, 267, 4]]\n",
      "--------------------------------------------------\n",
      "y 데이터 상위 2개\n",
      "[[6, 7, 8, 8, 8, 8, 8, 8, 8], [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]]\n",
      "--------------------------------------------------\n",
      "첫번째 샘플과 레이블의 길이\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print('X 데이터 상위 2개')\n",
    "print(encoded_X_train[:2])\n",
    "print('-' * 50)\n",
    "print('y 데이터 상위 2개')\n",
    "print(encoded_y_train[:2])\n",
    "print('-' * 50)\n",
    "print('첫번째 샘플과 레이블의 길이')\n",
    "print(len(encoded_X_train[0]))\n",
    "print(len(encoded_y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 78\n",
      "샘플의 평균 길이 : 14.518420\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('샘플의 최대 길이 : %d' % max(len(l) for l in encoded_X_train))\n",
    "print('샘플의 평균 길이 : %f' % (sum(map(len, encoded_X_train))/len(encoded_X_train)))\n",
    "plt.hist([len(s) for s in encoded_X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  count = 0\n",
    "  for sentence in nested_list:\n",
    "    if(len(sentence) <= max_len):\n",
    "        count = count + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 80 이하인 샘플의 비율: 100.0\n"
     ]
    }
   ],
   "source": [
    "max_len = 80\n",
    "below_threshold_len(max_len, encoded_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sentences, max_len):\n",
    "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        if len(sentence) != 0:\n",
    "            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기 : (8985, 80)\n",
      "검증 데이터의 크기 : (2247, 80)\n",
      "테스트 데이터의 크기 : (2809, 80)\n",
      "------------------------------\n",
      "훈련 데이터의 레이블 : (8985, 80)\n",
      "검증 데이터의 레이블 : (2247, 80)\n",
      "테스트 데이터의 레이블 : (2809, 80)\n"
     ]
    }
   ],
   "source": [
    "padded_X_train = pad_sequences(encoded_X_train, max_len=max_len)\n",
    "padded_X_valid = pad_sequences(encoded_X_valid, max_len=max_len)\n",
    "padded_X_test = pad_sequences(encoded_X_test, max_len=max_len)\n",
    "\n",
    "padded_y_train = pad_sequences(encoded_y_train, max_len=max_len)\n",
    "padded_y_valid = pad_sequences(encoded_y_valid, max_len=max_len)\n",
    "padded_y_test = pad_sequences(encoded_y_test, max_len=max_len)\n",
    "\n",
    "print('훈련 데이터의 크기 :', padded_X_train.shape)\n",
    "print('검증 데이터의 크기 :', padded_X_valid.shape)\n",
    "print('테스트 데이터의 크기 :', padded_X_test.shape)\n",
    "print('-' * 30)\n",
    "print('훈련 데이터의 레이블 :', padded_y_train.shape)\n",
    "print('검증 데이터의 레이블 :', padded_y_valid.shape)\n",
    "print('테스트 데이터의 레이블 :', padded_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 상위 샘플 2개\n",
      "[[1260 3215  117   17   21  123   56  539   23    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0]\n",
      " [5456   10 8229    9 8230  186   84 1815   11    8 1073    5  421    6\n",
      "  8231   35 2043  291  790  957  267    4    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0]]\n",
      "-----레이블-----\n",
      "[[6 7 8 8 8 8 8 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [9 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 상위 샘플 2개')\n",
    "print(padded_X_train[:2])\n",
    "print('-' * 5 + '레이블' + '-' * 5)\n",
    "print(padded_y_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu와 cuda 중 다음 기기로 학습함: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"cpu와 cuda 중 다음 기기로 학습함:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단방향 GRU\n",
    "# class NERTagger(nn.Module):\n",
    "#     def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "#         super(NERTagger, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "#         self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         embedded = self.embedding(x) \n",
    "#         gru_out, _ = self.gru(embedded) \n",
    "#         logits = self.fc(gru_out) \n",
    "#         return logits\n",
    "\n",
    "# Bidirectional LSTM\n",
    "class NERTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers=2):\n",
    "        super(NERTagger, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x) \n",
    "        lstm_out, _ = self.lstm(embedded) \n",
    "        logits = self.fc(lstm_out) \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(padded_X_train, dtype=torch.long)\n",
    "y_train_tensor = torch.tensor(padded_y_train, dtype=torch.long)\n",
    "X_valid_tensor = torch.tensor(padded_X_valid, dtype=torch.long)\n",
    "y_valid_tensor = torch.tensor(padded_y_valid, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(padded_X_test, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(padded_y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "valid_dataset = torch.utils.data.TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, shuffle=False, batch_size=32)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기: 16744\n"
     ]
    }
   ],
   "source": [
    "print('단어 집합의 크기:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim = tag_vocab_size\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NERTagger(\n",
       "  (embedding): Embedding(16744, 100)\n",
       "  (lstm): LSTM(100, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NERTagger(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(logits, labels, ignore_index=0):\n",
    "    predicted = torch.argmax(logits, dim=1)\n",
    "\n",
    "    mask = (labels != ignore_index)\n",
    "\n",
    "    correct = (predicted == labels).masked_select(mask).sum().item()\n",
    "    total = mask.sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valid_dataloader, criterion, device):\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in valid_dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            logits = model(batch_X)\n",
    "\n",
    "            loss = criterion(logits.view(-1, output_dim), batch_y.view(-1))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_correct += calculate_accuracy(logits.view(-1, output_dim), batch_y.view(-1)) * batch_y.size(0)\n",
    "            val_total += batch_y.size(0)\n",
    "\n",
    "    val_accuracy = val_correct / val_total\n",
    "    val_loss /= len(valid_dataloader)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "Train Loss: 0.3809, Train Accuracy: 0.8967\n",
      "Validation Loss: 0.2016, Validation Accuracy: 0.9409\n",
      "Validation loss improved from inf to 0.2016. 체크포인트를 저장합니다.\n",
      "Epoch 2/10:\n",
      "Train Loss: 0.1208, Train Accuracy: 0.9655\n",
      "Validation Loss: 0.1640, Validation Accuracy: 0.9561\n",
      "Validation loss improved from 0.2016 to 0.1640. 체크포인트를 저장합니다.\n",
      "Epoch 3/10:\n",
      "Train Loss: 0.0504, Train Accuracy: 0.9850\n",
      "Validation Loss: 0.1736, Validation Accuracy: 0.9592\n",
      "Epoch 4/10:\n",
      "Train Loss: 0.0342, Train Accuracy: 0.9891\n",
      "Validation Loss: 0.1703, Validation Accuracy: 0.9598\n",
      "Epoch 5/10:\n",
      "Train Loss: 0.0238, Train Accuracy: 0.9926\n",
      "Validation Loss: 0.1907, Validation Accuracy: 0.9604\n",
      "Epoch 6/10:\n",
      "Train Loss: 0.0215, Train Accuracy: 0.9929\n",
      "Validation Loss: 0.2149, Validation Accuracy: 0.9588\n",
      "Epoch 7/10:\n",
      "Train Loss: 0.0268, Train Accuracy: 0.9914\n",
      "Validation Loss: 0.2246, Validation Accuracy: 0.9567\n",
      "Epoch 8/10:\n",
      "Train Loss: 0.0261, Train Accuracy: 0.9919\n",
      "Validation Loss: 0.2129, Validation Accuracy: 0.9570\n",
      "Epoch 9/10:\n",
      "Train Loss: 0.0260, Train Accuracy: 0.9916\n",
      "Validation Loss: 0.2167, Validation Accuracy: 0.9570\n",
      "Epoch 10/10:\n",
      "Train Loss: 0.0281, Train Accuracy: 0.9910\n",
      "Validation Loss: 0.2623, Validation Accuracy: 0.9555\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_dataloader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        logits = model(batch_X)\n",
    "\n",
    "        loss = criterion(logits.view(-1, output_dim), batch_y.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += calculate_accuracy(logits.view(-1, output_dim), batch_y.view(-1)) * batch_y.size(0)\n",
    "        train_total += batch_y.size(0)\n",
    "\n",
    "    train_accuracy = train_correct / train_total\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f'Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. 체크포인트를 저장합니다.')\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model validation loss: 0.1640\n",
      "Best model validation accuracy: 0.9561\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
    "\n",
    "print(f'Best model validation loss: {val_loss:.4f}')\n",
    "print(f'Best model validation accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model test loss: 0.1605\n",
      "Best model test accuracy: 0.9571\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = evaluate(model, test_dataloader, criterion, device)\n",
    "\n",
    "print(f'Best model test loss: {test_loss:.4f}')\n",
    "print(f'Best model test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_tag = {}\n",
    "for key, value in tag_to_index.items():\n",
    "    index_to_tag[value] = key\n",
    "\n",
    "def predict_labels(text, model, word_to_ix, index_to_tag, max_len=150):\n",
    "    tokens = text.split()\n",
    "\n",
    "    token_indices = [word_to_ix.get(token, 1) for token in tokens]\n",
    "\n",
    "    token_indices_padded = np.zeros(max_len, dtype=int)\n",
    "    token_indices_padded[:len(token_indices)] = token_indices[:max_len]\n",
    "\n",
    "    input_tensor = torch.tensor(token_indices_padded, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)\n",
    "\n",
    "    predicted_indices = torch.argmax(logits, dim=-1).squeeze(0).tolist()\n",
    "\n",
    "    predicted_indices_no_pad = predicted_indices[:len(tokens)]\n",
    "\n",
    "    predicted_tags = [index_to_tag[index] for index in predicted_indices_no_pad]\n",
    "\n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feyenoord', 'rotterdam', 'suffered', 'an', 'early', 'shock', 'when', 'they', 'went', '1-0', 'down', 'after', 'four', 'minutes', 'against', 'de', 'graafschap', 'doetinchem', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feyenoord rotterdam suffered an early shock when they went 1-0 down after four minutes against de graafschap doetinchem .\n"
     ]
    }
   ],
   "source": [
    "sample = ' '.join(X_test[0])\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 : ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'I-PER', 'O']\n",
      "실제값 : ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O']\n"
     ]
    }
   ],
   "source": [
    "predicted_tags = predict_labels(sample, model, word_to_index, index_to_tag)\n",
    "print('예측 :', predicted_tags)\n",
    "print('실제값 :', y_test[0]) # 왜 내껀 성능이 별로지? ㅋ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
