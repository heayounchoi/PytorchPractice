{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq를 이용한 번역기 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 33000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "  # NFD: 유니코드 문자열을 정규화하는 방법 중 하나로, 악센트 문자를 기본 문자와 결합 문자로 분리함\n",
    "  # Mn: Non-Spacing Mark(악센트 등)를 나타내는 카테고리\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "  sent = unicode_to_ascii(sent.lower())\n",
    "  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "  sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "  return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "  encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "  with open(\"fra.txt\", \"r\") as lines:\n",
    "    for i, line in enumerate(lines):\n",
    "      src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "      src_line = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "      tar_line = preprocess_sentence(tar_line)\n",
    "      tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "      tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "      encoder_input.append(src_line)\n",
    "      decoder_input.append(tar_line_in)\n",
    "      decoder_target.append(tar_line_out)\n",
    "\n",
    "      if i == num_samples - 1:\n",
    "        break\n",
    "\n",
    "  return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 영어 문장 : Have you had dinner?\n",
      "전처리 후 영어 문장 : have you had dinner ?\n",
      "전처리 전 프랑스어 문장 : Avez-vous déjà diné?\n",
      "전처리 후 프랑스어 문장 : avez vous deja dine ?\n"
     ]
    }
   ],
   "source": [
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné?\"\n",
    "\n",
    "print('전처리 전 영어 문장 :', en_sent)\n",
    "print('전처리 후 영어 문장 :',preprocess_sentence(en_sent))\n",
    "print('전처리 전 프랑스어 문장 :', fr_sent)\n",
    "print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
      "디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n",
      "디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "print('인코더의 입력 :',sents_en_in[:5])\n",
    "print('디코더의 입력 :',sents_fra_in[:5])\n",
    "print('디코더의 레이블 :',sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sents):\n",
    "  word_list = []\n",
    "\n",
    "  for sent in sents:\n",
    "      for word in sent:\n",
    "        word_list.append(word)\n",
    "\n",
    "  word_counts = Counter(word_list)\n",
    "  vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "  word_to_index = {}\n",
    "  word_to_index['<PAD>'] = 0\n",
    "  word_to_index['<UNK>'] = 1\n",
    "\n",
    "  for index, word in enumerate(vocab) :\n",
    "    word_to_index[word] = index + 2\n",
    "\n",
    "  return word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4482, 프랑스어 단어 집합의 크기 : 7874\n"
     ]
    }
   ],
   "source": [
    "src_vocab = build_vocab(sents_en_in)\n",
    "tar_vocab = build_vocab(sents_fra_in + sents_fra_out)\n",
    "\n",
    "src_vocab_size = len(src_vocab)\n",
    "tar_vocab_size = len(tar_vocab)\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = {v: k for k, v in src_vocab.items()}\n",
    "index_to_tar = {v: k for k, v in tar_vocab.items()}\n",
    "\n",
    "def texts_to_sequences(sents, word_to_index):\n",
    "  encoded_X_data = []\n",
    "  for sent in tqdm(sents):\n",
    "    index_sequences = []\n",
    "    for word in sent:\n",
    "      try:\n",
    "          index_sequences.append(word_to_index[word])\n",
    "      except KeyError:\n",
    "          index_sequences.append(word_to_index['<UNK>'])\n",
    "    encoded_X_data.append(index_sequences)\n",
    "  return encoded_X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33000/33000 [00:00<00:00, 1598512.87it/s]\n",
      "100%|██████████| 33000/33000 [00:00<00:00, 389821.67it/s]\n",
      "100%|██████████| 33000/33000 [00:00<00:00, 2301573.58it/s]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = texts_to_sequences(sents_en_in, src_vocab)\n",
    "decoder_input = texts_to_sequences(sents_fra_in, tar_vocab)\n",
    "decoder_target = texts_to_sequences(sents_fra_out, tar_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 1, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 2, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 3, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 4, 정수 인코딩 전: ['hi', '.'], 정수 인코딩 후: [744, 2]\n"
     ]
    }
   ],
   "source": [
    "for i, (item1, item2) in zip(range(5), zip(sents_en_in, encoder_input)):\n",
    "    print(f\"Index: {i}, 정수 인코딩 전: {item1}, 정수 인코딩 후: {item2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sentences, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = max([len(sentence) for sentence in sentences])\n",
    "\n",
    "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        if len(sentence) != 0:\n",
    "            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input)\n",
    "decoder_input = pad_sequences(decoder_input)\n",
    "decoder_target = pad_sequences(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력의 크기(shape) : (33000, 7)\n",
      "디코더의 입력의 크기(shape) : (33000, 16)\n",
      "디코더의 레이블의 크기(shape) : (33000, 16)\n"
     ]
    }
   ],
   "source": [
    "print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n",
    "print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n",
    "print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 시퀀스 : [25263 19147  9236 ...   133 25292 14082]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print('랜덤 시퀀스 :',indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 's', 'your', 'key', '.', '<PAD>', '<PAD>']\n",
      "['<sos>', 'c', 'est', 'ta', 'clef', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['c', 'est', 'ta', 'clef', '.', '<eos>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "print([index_to_src[word] for word in encoder_input[30997]])\n",
    "print([index_to_tar[word] for word in decoder_input[30997]])\n",
    "print([index_to_tar[word] for word in decoder_target[30997]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터의 개수 : 3300\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(33000*0.1)\n",
    "print('검증 데이터의 개수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 source 데이터의 크기 : (29700, 7)\n",
      "훈련 target 데이터의 크기 : (29700, 16)\n",
      "훈련 target 레이블의 크기 : (29700, 16)\n",
      "테스트 source 데이터의 크기 : (3300, 7)\n",
      "테스트 target 데이터의 크기 : (3300, 16)\n",
      "테스트 target 레이블의 크기 : (3300, 16)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
    "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
    "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
    "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
    "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
    "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "embedding_dim = 256\n",
    "hidden_units = 256\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, src_vocab_size, embedding_dim, hidden_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(src_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (hidden, cell) = self.lstm(x)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, tar_vocab_size, embedding_dim, hidden_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(tar_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_units, tar_vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = self.embedding(x)\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        output = self.fc(output)\n",
    "        return output, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        hidden, cell = self.encoder(src)\n",
    "        output, _, _ = self.decoder(trg, hidden, cell)\n",
    "        return output\n",
    "\n",
    "encoder = Encoder(src_vocab_size, embedding_dim, hidden_units)\n",
    "decoder = Decoder(tar_vocab_size, embedding_dim, hidden_units)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(4482, 256, padding_idx=0)\n",
      "    (lstm): LSTM(256, 256, batch_first=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(7874, 256, padding_idx=0)\n",
      "    (lstm): LSTM(256, 256, batch_first=True)\n",
      "    (fc): Linear(in_features=256, out_features=7874, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader, loss_function, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for encoder_inputs, decoder_inputs, decoder_targets in dataloader:\n",
    "            encoder_inputs = encoder_inputs.to(device)\n",
    "            decoder_inputs = decoder_inputs.to(device)\n",
    "            decoder_targets = decoder_targets.to(device)\n",
    "\n",
    "            outputs = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "            loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            mask = decoder_targets != 0\n",
    "            total_correct += ((outputs.argmax(dim=-1) == decoder_targets) * mask).sum().item()\n",
    "            total_count += mask.sum().item()\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(4482, 256, padding_idx=0)\n",
       "    (lstm): LSTM(256, 256, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(7874, 256, padding_idx=0)\n",
       "    (lstm): LSTM(256, 256, batch_first=True)\n",
       "    (fc): Linear(in_features=256, out_features=7874, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_train_tensor = torch.tensor(encoder_input_train, dtype=torch.long)\n",
    "decoder_input_train_tensor = torch.tensor(decoder_input_train, dtype=torch.long)\n",
    "decoder_target_train_tensor = torch.tensor(decoder_target_train, dtype=torch.long)\n",
    "\n",
    "encoder_input_test_tensor = torch.tensor(encoder_input_test, dtype=torch.long)\n",
    "decoder_input_test_tensor = torch.tensor(decoder_input_test, dtype=torch.long)\n",
    "decoder_target_test_tensor = torch.tensor(decoder_target_test, dtype=torch.long)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = TensorDataset(encoder_input_train_tensor, decoder_input_train_tensor, decoder_target_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(encoder_input_test_tensor, decoder_input_test_tensor, decoder_target_test_tensor)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_epochs = 30\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 | Train Loss: 2.9672 | Train Acc: 0.5243 | Valid Loss: 3.0764 | Valid Acc: 0.5225\n",
      "Validation loss improved from inf to 3.0764. 체크포인트를 저장합니다.\n",
      "Epoch: 2/30 | Train Loss: 2.3057 | Train Acc: 0.5989 | Valid Loss: 2.5363 | Valid Acc: 0.5862\n",
      "Validation loss improved from 3.0764 to 2.5363. 체크포인트를 저장합니다.\n",
      "Epoch: 3/30 | Train Loss: 1.9080 | Train Acc: 0.6391 | Valid Loss: 2.2507 | Valid Acc: 0.6165\n",
      "Validation loss improved from 2.5363 to 2.2507. 체크포인트를 저장합니다.\n",
      "Epoch: 4/30 | Train Loss: 1.6071 | Train Acc: 0.6771 | Valid Loss: 2.0621 | Valid Acc: 0.6420\n",
      "Validation loss improved from 2.2507 to 2.0621. 체크포인트를 저장합니다.\n",
      "Epoch: 5/30 | Train Loss: 1.3605 | Train Acc: 0.7122 | Valid Loss: 1.9301 | Valid Acc: 0.6566\n",
      "Validation loss improved from 2.0621 to 1.9301. 체크포인트를 저장합니다.\n",
      "Epoch: 6/30 | Train Loss: 1.1463 | Train Acc: 0.7453 | Valid Loss: 1.8241 | Valid Acc: 0.6713\n",
      "Validation loss improved from 1.9301 to 1.8241. 체크포인트를 저장합니다.\n",
      "Epoch: 7/30 | Train Loss: 0.9599 | Train Acc: 0.7833 | Valid Loss: 1.7290 | Valid Acc: 0.6841\n",
      "Validation loss improved from 1.8241 to 1.7290. 체크포인트를 저장합니다.\n",
      "Epoch: 8/30 | Train Loss: 0.8057 | Train Acc: 0.8168 | Valid Loss: 1.6628 | Valid Acc: 0.6943\n",
      "Validation loss improved from 1.7290 to 1.6628. 체크포인트를 저장합니다.\n",
      "Epoch: 9/30 | Train Loss: 0.6732 | Train Acc: 0.8413 | Valid Loss: 1.6141 | Valid Acc: 0.7018\n",
      "Validation loss improved from 1.6628 to 1.6141. 체크포인트를 저장합니다.\n",
      "Epoch: 10/30 | Train Loss: 0.5743 | Train Acc: 0.8628 | Valid Loss: 1.5884 | Valid Acc: 0.7085\n",
      "Validation loss improved from 1.6141 to 1.5884. 체크포인트를 저장합니다.\n",
      "Epoch: 11/30 | Train Loss: 0.4809 | Train Acc: 0.8822 | Valid Loss: 1.5603 | Valid Acc: 0.7111\n",
      "Validation loss improved from 1.5884 to 1.5603. 체크포인트를 저장합니다.\n",
      "Epoch: 12/30 | Train Loss: 0.4154 | Train Acc: 0.8958 | Valid Loss: 1.5380 | Valid Acc: 0.7172\n",
      "Validation loss improved from 1.5603 to 1.5380. 체크포인트를 저장합니다.\n",
      "Epoch: 13/30 | Train Loss: 0.3621 | Train Acc: 0.9042 | Valid Loss: 1.5402 | Valid Acc: 0.7177\n",
      "Epoch: 14/30 | Train Loss: 0.3226 | Train Acc: 0.9110 | Valid Loss: 1.5334 | Valid Acc: 0.7206\n",
      "Validation loss improved from 1.5380 to 1.5334. 체크포인트를 저장합니다.\n",
      "Epoch: 15/30 | Train Loss: 0.2863 | Train Acc: 0.9160 | Valid Loss: 1.5448 | Valid Acc: 0.7212\n",
      "Epoch: 16/30 | Train Loss: 0.2645 | Train Acc: 0.9198 | Valid Loss: 1.5597 | Valid Acc: 0.7216\n",
      "Epoch: 17/30 | Train Loss: 0.2425 | Train Acc: 0.9224 | Valid Loss: 1.5720 | Valid Acc: 0.7221\n",
      "Epoch: 18/30 | Train Loss: 0.2264 | Train Acc: 0.9248 | Valid Loss: 1.5799 | Valid Acc: 0.7200\n",
      "Epoch: 19/30 | Train Loss: 0.2129 | Train Acc: 0.9266 | Valid Loss: 1.5917 | Valid Acc: 0.7215\n",
      "Epoch: 20/30 | Train Loss: 0.2026 | Train Acc: 0.9284 | Valid Loss: 1.5989 | Valid Acc: 0.7198\n",
      "Epoch: 21/30 | Train Loss: 0.1933 | Train Acc: 0.9292 | Valid Loss: 1.6136 | Valid Acc: 0.7202\n",
      "Epoch: 22/30 | Train Loss: 0.1870 | Train Acc: 0.9302 | Valid Loss: 1.6186 | Valid Acc: 0.7211\n",
      "Epoch: 23/30 | Train Loss: 0.1805 | Train Acc: 0.9307 | Valid Loss: 1.6294 | Valid Acc: 0.7202\n",
      "Epoch: 24/30 | Train Loss: 0.1790 | Train Acc: 0.9306 | Valid Loss: 1.6527 | Valid Acc: 0.7216\n",
      "Epoch: 25/30 | Train Loss: 0.1717 | Train Acc: 0.9312 | Valid Loss: 1.6570 | Valid Acc: 0.7198\n",
      "Epoch: 26/30 | Train Loss: 0.1687 | Train Acc: 0.9315 | Valid Loss: 1.6638 | Valid Acc: 0.7220\n",
      "Epoch: 27/30 | Train Loss: 0.1653 | Train Acc: 0.9314 | Valid Loss: 1.6730 | Valid Acc: 0.7198\n",
      "Epoch: 28/30 | Train Loss: 0.1629 | Train Acc: 0.9313 | Valid Loss: 1.6852 | Valid Acc: 0.7203\n",
      "Epoch: 29/30 | Train Loss: 0.1614 | Train Acc: 0.9320 | Valid Loss: 1.6889 | Valid Acc: 0.7225\n",
      "Epoch: 30/30 | Train Loss: 0.1590 | Train Acc: 0.9324 | Valid Loss: 1.6948 | Valid Acc: 0.7187\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for encoder_inputs, decoder_inputs, decoder_targets in train_dataloader:\n",
    "        encoder_inputs = encoder_inputs.to(device)\n",
    "        decoder_inputs = decoder_inputs.to(device)\n",
    "        decoder_targets = decoder_targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "        loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss, train_acc = evaluation(model, train_dataloader, loss_function, device)\n",
    "    valid_loss, valid_acc = evaluation(model, valid_dataloader, loss_function, device)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f}')\n",
    "\n",
    "    if valid_loss < best_val_loss:\n",
    "        print(f'Validation loss improved from {best_val_loss:.4f} to {valid_loss:.4f}. 체크포인트를 저장합니다.')\n",
    "        best_val_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model validation loss: 1.5334\n",
      "Best model validation accuracy: 0.7206\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "val_loss, val_accuracy = evaluation(model, valid_dataloader, loss_function, device)\n",
    "\n",
    "print(f'Best model validation loss: {val_loss:.4f}')\n",
    "print(f'Best model validation accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(tar_vocab['<sos>'])\n",
    "print(tar_vocab['<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = {v: k for k, v in src_vocab.items()}\n",
    "index_to_tar = {v: k for k, v in tar_vocab.items()}\n",
    "\n",
    "def seq_to_src(input_seq):\n",
    "  sentence = ''\n",
    "  for encoded_word in input_seq:\n",
    "    if(encoded_word != 0):\n",
    "      sentence = sentence + index_to_src[encoded_word] + ' '\n",
    "  return sentence\n",
    "\n",
    "def seq_to_tar(input_seq):\n",
    "  sentence = ''\n",
    "  for encoded_word in input_seq:\n",
    "    if(encoded_word != 0 and encoded_word != tar_vocab['<sos>'] and encoded_word != tar_vocab['<eos>']):\n",
    "      sentence = sentence + index_to_tar[encoded_word] + ' '\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 33 34 95  2  0  0]\n",
      "[   3   15 1502  174    2    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[  15 1502  174    2    4    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_test[25])\n",
    "print(decoder_input_test[25])\n",
    "print(decoder_target_test[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, max_output_len, int_to_src_token, int_to_tar_token):\n",
    "    encoder_inputs = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    hidden, cell = model.encoder(encoder_inputs)\n",
    "\n",
    "    decoder_input = torch.tensor([3], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    decoded_tokens = []\n",
    "\n",
    "    for _ in range(max_output_len):\n",
    "        output, hidden, cell = model.decoder(decoder_input, hidden, cell)\n",
    "\n",
    "        output_token = output.argmax(dim=-1).item()\n",
    "\n",
    "        if output_token == 4:\n",
    "            break\n",
    "\n",
    "        decoded_tokens.append(output_token)\n",
    "\n",
    "        decoder_input = torch.tensor([output_token], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    return ' '.join(int_to_tar_token[token] for token in decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : i need you . \n",
      "정답문장 : j ai besoin de vous . \n",
      "번역문장 : j ai besoin de toi .\n",
      "--------------------------------------------------\n",
      "입력문장 : i let the cat in . \n",
      "정답문장 : je laisse entrer le chat . \n",
      "번역문장 : je laisse entrer le chat .\n",
      "--------------------------------------------------\n",
      "입력문장 : is it working ? \n",
      "정답문장 : ca marche ? \n",
      "번역문장 : ca marche ?\n",
      "--------------------------------------------------\n",
      "입력문장 : is tom there too ? \n",
      "정답문장 : est ce que tom est la aussi ? \n",
      "번역문장 : est ce que tom est la aussi ?\n",
      "--------------------------------------------------\n",
      "입력문장 : how s the wife ? \n",
      "정답문장 : comment se porte ta femme ? \n",
      "번역문장 : comment est ce dans le numero ?\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3, 50, 100, 300, 1001]:\n",
    "  input_seq = encoder_input_train[seq_index]\n",
    "  translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
    "\n",
    "  print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
    "  print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
    "  print(\"번역문장 :\",translated_text)\n",
    "  print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : hurry up girls . \n",
      "정답문장 : grouillez vous les filles ! \n",
      "번역문장 : on se magne les filles !\n",
      "--------------------------------------------------\n",
      "입력문장 : the ice melted . \n",
      "정답문장 : la glace a fondu . \n",
      "번역문장 : la coupe la guerre .\n",
      "--------------------------------------------------\n",
      "입력문장 : i can afford it . \n",
      "정답문장 : j en ai les moyens . \n",
      "번역문장 : je n y peux pas le coup .\n",
      "--------------------------------------------------\n",
      "입력문장 : tom was on time . \n",
      "정답문장 : tom etait a l heure . \n",
      "번역문장 : tom etait sur le temps .\n",
      "--------------------------------------------------\n",
      "입력문장 : you re bright . \n",
      "정답문장 : vous etes brillante . \n",
      "번역문장 : vous etes brillantes .\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3, 50, 100, 300, 1001]:\n",
    "  input_seq = encoder_input_test[seq_index]\n",
    "  translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
    "\n",
    "  print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
    "  print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
    "  print(\"번역문장 :\",translated_text)\n",
    "  print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
