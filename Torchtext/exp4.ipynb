{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torchtext - batch_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('IMDb_Reviews.csv', <http.client.HTTPMessage at 0x11efa38d0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDb_Reviews.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 개수 : 50000\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 개수 : {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[:25000]\n",
    "test_df = df[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_data.csv\", index=False)\n",
    "test_df.to_csv(\"test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "\n",
    "TEXT = data.Field(sequential=True,\n",
    "                  use_vocab=True,\n",
    "                  tokenize=str.split,\n",
    "                  lower=True,\n",
    "                  batch_first=True, # 기본값 False\n",
    "                  fix_length=20)\n",
    "\n",
    "LABEL = data.Field(sequential=False,\n",
    "                   use_vocab=False,\n",
    "                   batch_first=False,\n",
    "                   is_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  81,    3,   49,   56,  274,    0,  380,    0,   83,  115,  145,    9,\n",
      "          113,   10,   20,    9,   39,  113,    0,    7],\n",
      "        [   9,  260,    2,    0,  227,  393,    4,    2,  850,   12,  244,    6,\n",
      "          429,    7,    0,   11,    7,    3,  850,   22],\n",
      "        [5363,    5,    0,    7,  362,   22,  192,   81,    0,  130, 7048, 5420,\n",
      "          563,  417,    0,   18,   33,   86,  107,    6],\n",
      "        [  10,  150,  192,  879,    7,    2,  119,    9,   26, 1602,    4,   61,\n",
      "          275,   48,  638,  768,   62, 1298,   43,  364],\n",
      "        [   9,  217,   49, 1750,   31,    2,  903,  186,  310,    5,   10,   25,\n",
      "           69, 1279,    0, 5215,    4, 7767,   69,  512]])\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import Iterator\n",
    "\n",
    "train_data, test_data = TabularDataset.splits(\n",
    "        path='.', train='train_data.csv', test='test_data.csv', format='csv',\n",
    "        fields=[('text', TEXT), ('label', LABEL)], skip_header=True)\n",
    "\n",
    "TEXT.build_vocab(train_data, min_freq=10, max_size=10000)\n",
    "\n",
    "batch_size = 5\n",
    "train_loader = Iterator(dataset=train_data, batch_size = batch_size)\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "print(batch.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 20])\n"
     ]
    }
   ],
   "source": [
    "print(batch.text.shape) # (배치 크기 X fix_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential=True,\n",
    "                  use_vocab=True,\n",
    "                  tokenize=str.split,\n",
    "                  lower=True,\n",
    "                  fix_length=20)\n",
    "\n",
    "LABEL = data.Field(sequential=False,\n",
    "                   use_vocab=False,\n",
    "                   batch_first=False,\n",
    "                   is_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  81,    9, 5363,   10,    9],\n",
      "        [   3,  260,    5,  150,  217],\n",
      "        [  49,    2,    0,  192,   49],\n",
      "        [  56,    0,    7,  879, 1750],\n",
      "        [ 274,  227,  362,    7,   31],\n",
      "        [   0,  393,   22,    2,    2],\n",
      "        [ 380,    4,  192,  119,  903],\n",
      "        [   0,    2,   81,    9,  186],\n",
      "        [  83,  850,    0,   26,  310],\n",
      "        [ 115,   12,  130, 1602,    5],\n",
      "        [ 145,  244, 7048,    4,   10],\n",
      "        [   9,    6, 5420,   61,   25],\n",
      "        [ 113,  429,  563,  275,   69],\n",
      "        [  10,    7,  417,   48, 1279],\n",
      "        [  20,    0,    0,  638,    0],\n",
      "        [   9,   11,   18,  768, 5215],\n",
      "        [  39,    7,   33,   62,    4],\n",
      "        [ 113,    3,   86, 1298, 7767],\n",
      "        [   0,  850,  107,   43,   69],\n",
      "        [   7,   22,    6,  364,  512]])\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import Iterator\n",
    "\n",
    "train_data, test_data = TabularDataset.splits(\n",
    "        path='.', train='train_data.csv', test='test_data.csv', format='csv',\n",
    "        fields=[('text', TEXT), ('label', LABEL)], skip_header=True)\n",
    "\n",
    "TEXT.build_vocab(train_data, min_freq=10, max_size=10000)\n",
    "\n",
    "batch_size = 5\n",
    "train_loader = Iterator(dataset=train_data, batch_size = batch_size)\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "print(batch.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5])\n"
     ]
    }
   ],
   "source": [
    "print(batch.text.shape) # (fix_length X 배치 크기)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
